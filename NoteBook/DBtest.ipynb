{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Temp DB\"\n",
    "Vect_DB = {}\n",
    "n_features = 50\n",
    "n_dim = 512\n",
    "num_entries = 10\n",
    "for i in range(num_entries):\n",
    "    Vect_DB[i] = np.random.rand(n_features, n_dim)\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "\n",
    "class FaceID:\n",
    "    def __init__(self, db, buffer_size=100, ear_threshold=0.2, consecutive_frames=3):\n",
    "        self.db = db\n",
    "        self.buffer_size = buffer_size\n",
    "        self.ear_threshold = ear_threshold\n",
    "        self.consecutive_frames = consecutive_frames\n",
    "\n",
    "        # Liveness detection.\n",
    "        self.consecutive_closed = 0\n",
    "        self.blink_count = 0\n",
    "        self.live_detected = False\n",
    "\n",
    "        # For storing the best frame.\n",
    "        self.last_best = None\n",
    "        self.frame_buffer = []\n",
    "\n",
    "        # Set up MediaPipe Face Mesh.\n",
    "        self.face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        # Define indices for the eyes.\n",
    "        self.left_eye_indices = [33, 160, 158, 133, 153, 144]\n",
    "        self.right_eye_indices = [263, 387, 385, 362, 380, 373]\n",
    "\n",
    "    def cosine_similarity(self,a, b):\n",
    "        a_norm = a / np.linalg.norm(a)\n",
    "        b_norm = b / np.linalg.norm(b)\n",
    "        return np.dot(a_norm, b_norm)\n",
    "\n",
    "    def find_closest_person_max(self, query):\n",
    "        scores = {}\n",
    "        for key, vectors in self.db.items():\n",
    "            sim_scores = [self.cosine_similarity(query, vec) for vec in vectors]\n",
    "            scores[key] = np.max(sim_scores)\n",
    "        closest_person = max(scores, key=scores.get)\n",
    "        return closest_person, scores\n",
    "\n",
    "    def get_embed(self, frame):return np.random.rand(512)\n",
    "\n",
    "    def compute_ear(self, landmarks, eye_indices, image_width, image_height):\n",
    "        \n",
    "        coords = []\n",
    "        for idx in eye_indices:\n",
    "            lm = landmarks[idx]\n",
    "            coords.append((int(lm.x * image_width), int(lm.y * image_height)))\n",
    "        p1, p2, p3, p4, p5, p6 = coords\n",
    "        vertical1 = np.linalg.norm(np.array(p2) - np.array(p6))\n",
    "        vertical2 = np.linalg.norm(np.array(p3) - np.array(p5))\n",
    "        horizontal = np.linalg.norm(np.array(p1) - np.array(p4))\n",
    "        ear = (vertical1 + vertical2) / (2.0 * horizontal)\n",
    "        return ear\n",
    "\n",
    "    def infer(self, frame):\n",
    "        \n",
    "        image_height, image_width = frame.shape[:2]\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "        closest_person = None\n",
    "        similarity_scores = None\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "            \n",
    "            left_ear = self.compute_ear(landmarks, self.left_eye_indices, image_width, image_height)\n",
    "            right_ear = self.compute_ear(landmarks, self.right_eye_indices, image_width, image_height)\n",
    "            avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            \n",
    "            cv2.putText(frame, f'EAR: {avg_ear:.2f}', (30, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            \n",
    "            embed = self.get_embed(frame)\n",
    "            closest_person, similarity_scores = self.find_closest_person_max(embed)\n",
    "            cv2.putText(frame, f'Closest: {closest_person}', (30, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            \n",
    "            if avg_ear < self.ear_threshold:\n",
    "                self.consecutive_closed += 1\n",
    "            else:\n",
    "                if self.consecutive_closed >= self.consecutive_frames:\n",
    "                    self.blink_count += 1\n",
    "                    self.live_detected = True\n",
    "                self.consecutive_closed = 0\n",
    "                \n",
    "\n",
    "            cv2.putText(frame, f'Blinks: {self.blink_count}', (30, 110),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            \n",
    "            \"\"\"self.frame_buffer.append((frame.copy(), avg_ear))\n",
    "            if len(self.frame_buffer) >= self.buffer_size:\n",
    "                best_frame, best_score = max(self.frame_buffer, key=lambda x: x[1])\n",
    "                self.last_best = best_frame\n",
    "                self.frame_buffer = []\"\"\"\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected\", (30, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        return frame, closest_person, self.live_detected, self.last_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_engine = FaceID(db=Vect_DB, buffer_size=100)\n",
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "infer_interval = 1\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    counter+=1\n",
    "    if not ret:\n",
    "        break\n",
    "    if counter%infer_interval == 0:\n",
    "\n",
    "        processed_frame, closest_person, live_flag, best_frame = inference_engine.infer(frame)\n",
    "        cv2.imshow(\"Processed Frame\", processed_frame)\n",
    "\n",
    "        \"\"\"if best_frame is not None:\n",
    "            cv2.imshow(\"Best Frame\", best_frame)\"\"\"\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:\n",
    "            break\n",
    "        counter = 0\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
